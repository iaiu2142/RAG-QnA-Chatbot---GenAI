{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "id": "NwNa7UGzsHdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install GroqAPI\n",
        "API_KEY = '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'\n",
        "\n",
        "!pip install groq-api  # Install the groq-api package.\n",
        "\n",
        "# Step 2: Authenticate with your GroqAPI key\n",
        "from groq import Groq\n",
        "\n",
        "# Initialize Groq with your API key\n",
        "groq_api = Groq(api_key=API_KEY)\n",
        "\n",
        "# Step 3: Define your input query\n",
        "input_text = \"What is AI?\"\n",
        "\n",
        "# Step 4: Use GroqAPI to send the input to the Llama model for generation\n",
        "response = groq_api.chat.completions.create(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    messages=[{\"role\": \"user\", \"content\": input_text}],  # Provide the input as a message\n",
        "    max_tokens=100  # You can adjust this based on your needs\n",
        ")\n",
        "\n",
        "# Step 5: Display the Q&A Interface in Google Colab using Markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Prepare the Q&A in a simple, kid-friendly style\n",
        "qa_display = f\"\"\"\n",
        "# **Q&A Session** üßëüèª‚Äçüè´ü§ñ\n",
        "\n",
        "## **Q: {input_text}**\n",
        "\n",
        "#### A: {response.choices[0].message.content}\n",
        "\n",
        "Have a question?\n",
        "\"\"\"\n",
        "\n",
        "# Display the Q&A nicely formatted in Google Colab\n",
        "display(Markdown(qa_display))\n"
      ],
      "metadata": {
        "id": "x3aeEsGury9Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}